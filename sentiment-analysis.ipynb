{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# data preprocessing\n",
    "from html import unescape\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# building the model\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# serialization\n",
    "import gzip\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "mkdir data\n",
    "wget http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip -nc -P ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "b'Skipping line 8836: expected 4 fields, saw 5\\n'\nb'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ItemID  Sentiment SentimentSource  \\\n0       1          0    Sentiment140   \n1       2          0    Sentiment140   \n2       3          1    Sentiment140   \n3       4          0    Sentiment140   \n4       5          0    Sentiment140   \n\n                                       SentimentText  \n0                       is so sad for my APL frie...  \n1                     I missed the New Moon trail...  \n2                            omg its already 7:30 :O  \n3            .. Omgaga. Im sooo  im gunna CRy. I'...  \n4           i think mi bf is cheating on me!!!   ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ItemID</th>\n      <th>Sentiment</th>\n      <th>SentimentSource</th>\n      <th>SentimentText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>is so sad for my APL frie...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>I missed the New Moon trail...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>Sentiment140</td>\n      <td>omg its already 7:30 :O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>Sentiment140</td>\n      <td>i think mi bf is cheating on me!!!   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('data/Sentiment-Analysis-Dataset.zip', error_bad_lines=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating functions for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# alternative: from nltk import TweetTokenizer\n",
    "def preprocessor(doc):\n",
    "    return unescape(doc).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'tagger'])\n",
    "\n",
    "def lemmatizer(doc):\n",
    "    return [word.lemma_ for word in nlp(doc)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# lemmatization of STOP_WORDS\n",
    "STOP_WORDS_lemma = [word.lemma_ for word in nlp(\" \".join(list(STOP_WORDS)))]\n",
    "STOP_WORDS_lemma = set(STOP_WORDS_lemma).union({',', '.', ';'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(preprocessor=preprocessor,\n",
    "                               alternate_sign=False,\n",
    "                               #tokenizer=lemmatizer, \n",
    "                               #ngram_range=(1,2),\n",
    "                               stop_words=STOP_WORDS)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "pipe = Pipeline([('vectorizer', vectorizer), ('classifier', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['SentimentText']\n",
    "y = df['Sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training R^2: {}'.format(pipe.score(X_train, y_train)))\n",
    "print('Testing R^2: {}'.format(pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize the model to persistent storage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with gzip.open('sentiment_model.dill.gz', 'wb') as f:\n",
    "    dill.dump(pipe, f, recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -alh sentiment_model.dill.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Persistent model testing R^2: 0.7699090658583632\n"
    }
   ],
   "source": [
    "with gzip.open('sentiment_model.dill.gz', 'rb') as f:\n",
    "    model = dill.load(f)\n",
    "\n",
    "print('Persistent model testing R^2: {}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598609997127"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}